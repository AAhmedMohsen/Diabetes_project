# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TVoPke1O1kthq5iTxL5e5637HO7AFMX9
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("/content/diabetes_prediction_dataset.csv")
df

df.shape

df.info()

df.describe().T

#check if there is Null values in data or not
df.isnull().sum().sum()

#check if there is duplicate values in data or not
df.duplicated().sum()

#Removing the duplicated values
df.drop_duplicates(inplace=True)

df.duplicated().sum()

plt.figure(figsize=(6,4))
sns.countplot(x="smoking_history", data=df)
plt.title("Smoking History Distribution")
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(x="diabetes", data=df)
plt.title("Diabetes Distribution")
plt.show()

df.hist(figsize=(12,12))

df['gender'].unique()

df["gender"]=df["gender"].str.replace("Other","Male")

plt.figure(figsize=(6,4))
sns.countplot(x="gender", data=df, palette="coolwarm")
plt.title("Gender Distribution")
plt.show()

le = LabelEncoder()
df['gender'] = le.fit_transform(df['gender'])
# One-hot encode the 'smoking_history' column
df = pd.get_dummies(df, columns=['smoking_history'], drop_first=True)
df.head(15)

bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)
df.head(15)

numerical_cols = ['age','bmi', 'HbA1c_level', 'blood_glucose_level']
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

X = df.drop('diabetes',axis=1)
y = df['diabetes']
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state=22)

lr_model = LogisticRegression()
lr_model.fit(X_train,y_train)

y_pred = lr_model.predict(X_test)
print( accuracy_score(y_test,y_pred)*100)
print()
conf = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf,annot=True,fmt='d')
plt.title("Confusion Matrix")
plt.show()
print()
print(classification_report(y_test,y_pred))

rf_model = RandomForestClassifier()
rf_model.fit(X_train,y_train)

y_pred = rf_model.predict(X_test)
print( accuracy_score(y_test,y_pred)*100)
print()
conf = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf,annot=True,fmt='d', cmap='viridis')
plt.title("Confusion Matrix")
plt.show()
print()
print(classification_report(y_test,y_pred))

knn_model = KNeighborsClassifier()
knn_model.fit(X_train,y_train)

y_pred = knn_model.predict(X_test)
print( accuracy_score(y_test,y_pred)*100)
print()
conf = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf,annot=True,fmt='d', cmap='coolwarm')
plt.title("Confusion Matrix")
plt.show()
print()
print(classification_report(y_test,y_pred))

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train,y_train)

y_pred = dt_model.predict(X_test)
print( accuracy_score(y_test,y_pred)*100)
print()
conf = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf,annot=True,fmt='d', cmap='Reds')
plt.title("Confusion Matrix")
plt.show()
print()
print(classification_report(y_test,y_pred))

def evaluate_and_plot_models(X_test, y_test, lr_model, rf_model, dt_model, knn_model):
    models = {
        'Logistic Regression': lr_model,
        'Random Forest': rf_model,
        'Decision Tree': dt_model,
        'KNN': knn_model
    }

    metrics = {'Model': [], 'Accuracy ': [], 'Precision ': [], 'Recall ': [], 'F1 Score ': []}

    for name, model in models.items():
        y_pred = model.predict(X_test)
        metrics['Model'].append(name)
        metrics['Accuracy '].append(accuracy_score(y_test, y_pred) * 100)
        metrics['Precision '].append(precision_score(y_test, y_pred, zero_division=0) * 100)
        metrics['Recall '].append(recall_score(y_test, y_pred, zero_division=0) * 100)
        metrics['F1 Score '].append(f1_score(y_test, y_pred, zero_division=0) * 100)

    results_df = pd.DataFrame(metrics)
    results_df.set_index('Model', inplace=True)

    # Plot with percentage y-axis
    plt.figure(figsize=(12, 6))
    results_df.plot(kind='bar', colormap='Purples')
    plt.title('Model Performance Comparison')
    plt.ylabel('Score')
    plt.ylim(0, 100)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.xticks(rotation=0)
    plt.tight_layout()
    plt.legend(loc='lower right')
    plt.show()

    return results_df

#Example:
df_results = evaluate_and_plot_models(X_test, y_test, lr_model, rf_model, dt_model, knn_model)

# System Predict
input_data = (0, 44.0, 0, 0, 19.31, 6.5, 200, 0, 0, 0, 1, 0)
# Convert to numpy and reshape
input_data_as_numpy_array = np.asarray(input_data).reshape(1, -1)

scaled_values = scaler.transform(np.asarray([[input_data[1], input_data[4], input_data[5], input_data[6]]]))

# Replace the scaled values into the array
input_data_scaled = list(input_data)
input_data_scaled[1] = scaled_values[0][0]  # age
input_data_scaled[4] = scaled_values[0][1]  # bmi
input_data_scaled[5] = scaled_values[0][2]  # HbA1c
input_data_scaled[6] = scaled_values[0][3]  # glucose

# Final input
final_input = np.asarray(input_data_scaled).reshape(1, -1)

# Make prediction using any model, e.g., rf_model
prediction = rf_model.predict(final_input)

if prediction[0] == 1:
    print("The person is diabetic.")
else:
    print("The person is not diabetic.")

